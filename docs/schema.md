# Schema Information

__NB__: Unless explicitly excluded, all tables will contain timestamps.

## Statically Defined Tables:
These tables are defined in the schema and generated by migrations.

### charts
column name | data type | details
------------|-----------|-----------------------
id ðŸ”‘       | integer   | not null, primary key
options     | json      | not null
user_id     | integer   | not null, foreign key (references users), indexed
dataset_id  | integer   | not null, foreign key (references notebooks), indexed

### datasets
column name   | data type | details
--------------|-----------|-----------------------
id ðŸ”‘         | integer   | not null, primary key
dataset_id    | string    | not null
user_id       | integer   | not null, foreign key (references notes), indexed, unique [tag_id]

### users
column name     | data type | details
----------------|-----------|-----------------------
id ðŸ”‘           | integer   | not null, primary key
email_address   | string    | not null, indexed, unique
password_digest | string    | not null
session_token   | string    | not null, indexed, unique

## Dynamically Defined Tables:
I don't know the "right" way to store user uploaded csv files in a way that
they can be later queried via SQL, so I'm going to say we'll just add a new
table for each data set. I'm not sure what the implications of this will be.

### [dataset_id]
column name     | data type | details
----------------|-----------|-----------------------
To be uploaded by users.
